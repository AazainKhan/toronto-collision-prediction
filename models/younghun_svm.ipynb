{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../cleaned_data_KSI.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = df.drop('ACCLASS', axis=1)\n",
    "y = df['ACCLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.3, random_state=5, stratify=y_encoded)\n",
    "\n",
    "# Define transformations\n",
    "numeric_features = X_train.select_dtypes(\n",
    "    include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(\n",
    "    include=['object']).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = ImPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=5)),\n",
    "    ('classifier', SVC(random_state=5, probability=True))\n",
    "])\n",
    "\n",
    "# Evaluate model before hyperparameter tuning\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "y_pred_before = model.predict(X_test)\n",
    "y_probs_before = model.predict_proba(X_test)[:, 1]\n",
    "accuracy_before = accuracy_score(y_test, y_pred_before)\n",
    "precision_before = precision_score(y_test, y_pred_before, average=None)\n",
    "recall_before = recall_score(y_test, y_pred_before, average=None)\n",
    "f1_before = f1_score(y_test, y_pred_before, average=None)\n",
    "auc_roc_before = roc_auc_score(y_test, y_probs_before)\n",
    "conf_matrix_before = confusion_matrix(y_test, y_pred_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tuning:\n",
      "Accuracy: 0.8573584905660377\n",
      "Precision per class: [0.49006623 0.94885694]\n",
      "Recall per class: [0.7047619  0.88192771]\n",
      "F1 Score per class: [0.578125   0.91416894]\n",
      "AUC-ROC: 0.8972705664960396\n",
      "Confusion Matrix:\n",
      " [[ 518  217]\n",
      " [ 539 4026]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Tuning:\")\n",
    "print(f\"Accuracy: {accuracy_before}\")\n",
    "print(\"Precision per class:\", precision_before)\n",
    "print(\"Recall per class:\", recall_before)\n",
    "print(\"F1 Score per class:\", f1_before)\n",
    "print(\"AUC-ROC:\", auc_roc_before)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END classifier__C=10, classifier__gamma=scale, classifier__kernel=poly; total time=  26.2s\n",
      "[CV] END classifier__C=10, classifier__gamma=scale, classifier__kernel=poly; total time=  25.4s\n",
      "[CV] END classifier__C=10, classifier__gamma=scale, classifier__kernel=poly; total time=  25.4s\n",
      "[CV] END classifier__C=10, classifier__gamma=1, classifier__kernel=rbf; total time= 2.4min\n",
      "[CV] END classifier__C=10, classifier__gamma=1, classifier__kernel=rbf; total time= 2.5min\n",
      "[CV] END classifier__C=10, classifier__gamma=1, classifier__kernel=rbf; total time= 2.4min\n",
      "[CV] END classifier__C=10, classifier__gamma=auto, classifier__kernel=poly; total time=  52.6s\n",
      "[CV] END classifier__C=10, classifier__gamma=auto, classifier__kernel=poly; total time= 9.1min\n",
      "[CV] END classifier__C=10, classifier__gamma=auto, classifier__kernel=poly; total time=35.2min\n",
      "[CV] END classifier__C=100, classifier__gamma=0.01, classifier__kernel=poly; total time=  46.0s\n",
      "[CV] END classifier__C=100, classifier__gamma=0.01, classifier__kernel=poly; total time=  46.3s\n",
      "[CV] END classifier__C=100, classifier__gamma=0.01, classifier__kernel=poly; total time=  45.1s\n",
      "[CV] END classifier__C=100, classifier__gamma=0.1, classifier__kernel=sigmoid; total time=  51.0s\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
    "    'classifier__kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Configure RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_distributions,\n",
    "                                   n_iter=10, cv=3, verbose=2, random_state=5, scoring='accuracy')\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and its parameters\n",
    "best_params = random_search.best_params_\n",
    "best_estimator = random_search.best_estimator_\n",
    "mean_cv_score = random_search.best_score_\n",
    "print(\"After Tuning:\")\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Estimator:\", best_estimator)\n",
    "print(\"Mean Cross Validation Score:\", mean_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set after tuning\n",
    "y_pred_after = best_estimator.predict(X_test)\n",
    "y_probs_after = best_estimator.predict_proba(X_test)[:, 1]\n",
    "accuracy_after = accuracy_score(y_test, y_pred_after)\n",
    "precision_after = precision_score(y_test, y_pred_after, average=None)\n",
    "recall_after = recall_score(y_test, y_pred_after, average=None)\n",
    "f1_after = f1_score(y_test, y_pred_after, average=None)\n",
    "auc_roc_after = roc_auc_score(y_test, y_probs_after)\n",
    "conf_matrix_after = confusion_matrix(y_test, y_pred_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After Tuning:\")\n",
    "print(f\"Accuracy: {accuracy_after}\")\n",
    "print(\"Precision per class:\", precision_after)\n",
    "print(\"Recall per class:\", recall_after)\n",
    "print(\"F1 Score per class:\", f1_after)\n",
    "print(\"AUC-ROC:\", auc_roc_after)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate metrics for each class specifically if needed\n",
    "if len(np.unique(y)) > 1:\n",
    "    class_labels = label_encoder.classes_\n",
    "    for index, label in enumerate(class_labels):\n",
    "        print(f\"{label} - Precision: {precision_after[index]}\")\n",
    "        print(f\"{label} - Recall: {recall_after[index]}\")\n",
    "        print(f\"{label} - F1 Score: {f1_after[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "fpr_after, tpr_after, _ = roc_curve(y_test, y_probs_after)\n",
    "plt.plot(fpr_after, tpr_after, color='darkorange', lw=2,\n",
    "         label='ROC curve (area = %0.2f)' % auc_roc_after)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic After Tuning')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
